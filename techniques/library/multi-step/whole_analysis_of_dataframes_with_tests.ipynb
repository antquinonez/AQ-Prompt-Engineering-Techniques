{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A whole program to do an analysis of dataframes, complete with tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- ChatGPT4, browser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- The prompt here excludes project specific details that are not relevant here and are trivial to code (especially nowadays :) )\n",
    "# -- I had to ask ChatGPT to continue its output because it had provided an incomplete code fragment to Prompt 1. I just asked 'continue'. \n",
    "# -- I had to copy code that fell out of the code window that ChatGPT uses.\n",
    "# -- I had to edit the generated text to add a closing multi line comment with triple quotes. ChatGPT output starts to pause and choke when it gets very long."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ChatGPT to provide a complete, high feature program to solve an actual data analysis task I needed to solve. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I needed to compare one set with another set of multiple CSV files. I needed to see:\n",
    "# -- If the set of columns were the same\n",
    "# --   If there were differences, what the differences were\n",
    "# -- If the order of the columns was different\n",
    "# -- If the datatype for columns in common were the same\n",
    "# --   If there were differences, sample values for those differences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Functional Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanted to describe the full program upfront.\n",
    "# I wanted to use functions to make the code more readable.\n",
    "# I wanted to have functions with type hints., because type hints are awesome.\n",
    "# I wanted to document the functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 1 -- Create the program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to compare the data profile between two pandas dataframes. Look at the column names and provide an analysis of what's not in common. If column name order is different, print out the order of the columns. For columns in common, identify if the column data types are different. When there's a difference between data types, provide 3 sample values from each dataframe column. Breakdown the program into functions with type hints, and document the functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "def compare_columns(df1: pd.DataFrame, df2: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Compare columns between two dataframes.\n",
    "\n",
    "    :param df1: First dataframe\n",
    "    :param df2: Second dataframe\n",
    "    :return: A tuple with two lists: the first contains columns not in common, the second contains columns with different order\n",
    "    \"\"\"\n",
    "    not_in_common = list(set(df1.columns) ^ set(df2.columns))\n",
    "    diff_order = [col for col in df1.columns if df1.columns.get_loc(col) != df2.columns.get_loc(col)]\n",
    "\n",
    "    return not_in_common, diff_order\n",
    "\n",
    "def compare_data_types(df1: pd.DataFrame, df2: pd.DataFrame, common_columns: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Compare data types of common columns between two dataframes.\n",
    "\n",
    "    :param df1: First dataframe\n",
    "    :param df2: Second dataframe\n",
    "    :param common_columns: List of common columns between two dataframes\n",
    "    :return: A list of columns with different data types\n",
    "    \"\"\"\n",
    "    diff_data_types = [col for col in common_columns if df1[col].dtype != df2[col].dtype]\n",
    "    return diff_data_types\n",
    "\n",
    "def get_sample_values(df1: pd.DataFrame, df2: pd.DataFrame, diff_data_types: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Print 3 sample values from each dataframe column for columns with different data types.\n",
    "\n",
    "    :param df1: First dataframe\n",
    "    :param df2: Second dataframe\n",
    "    :param diff_data_types: List of columns with different data types\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    for col in diff_data_types:\n",
    "        print(f\"Column '{col}' has different data types.\")\n",
    "        print(f\"Sample values from DataFrame 1: {df1[col].dropna().sample(3).values}\")\n",
    "        print(f\"Sample values from DataFrame 2: {df2[col].dropna().sample(3).values}\")\n",
    "        print()\n",
    "\n",
    "def data_profile_comparison(df1: pd.DataFrame, df2: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Compare the data profile between two dataframes.\n",
    "\n",
    "    :param df1: First dataframe\n",
    "    :param df2: Second dataframe\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    not_in_common, diff_order = compare_columns(df1, df2)\n",
    "\n",
    "    if not_in_common:\n",
    "        print(f\"Columns not in common: {', '.join(not_in_common)}\")\n",
    "    else:\n",
    "        print(\"Both dataframes have the same columns.\")\n",
    "\n",
    "    if diff_order:\n",
    "        print(f\"Columns with different order: {', '.join(diff_order)}\")\n",
    "    else:\n",
    "        print(\"Both dataframes have the same column order.\")\n",
    "\n",
    "    common_columns = list(set(df1.columns) & set(df2.columns))\n",
    "    diff_data_types = compare_data_types(df1, df2, common_columns)\n",
    "\n",
    "    if diff_data_types:\n",
    "        get_sample_values(df1, df2, diff_data_types)\n",
    "    else:\n",
    "        print(\"All common columns have the same data types.\")\n",
    "    \n",
    "# # Example usage:\n",
    "# data1 = {\n",
    "# 'A': [1, 2, 3],\n",
    "# 'B': [4.1, 5.2, 6.3],\n",
    "# 'C': ['a', 'b', 'c']\n",
    "# }\n",
    "\n",
    "# data2 = {\n",
    "# 'B': [7, 8, 9],\n",
    "# 'A': [1.1, 2.2, 3.3],\n",
    "# 'D': ['x', 'y', 'z']\n",
    "# }\n",
    "\n",
    "# df1 = pd.DataFrame(data1)\n",
    "# df2 = pd.DataFrame(data2)\n",
    "\n",
    "# data_profile_comparison(df1, df2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt 2 -- And write some tests for the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:\n",
    "# -- First time that I executed this, I received a function with some tests. This time, I received a class-based solution.\n",
    "# -- I've used pytest in the past, but not unittest based tests. Cool. Now I see that works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestDataProfileComparison(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.data1 = {\n",
    "            'A': [1, 2, 3],\n",
    "            'B': [4.1, 5.2, 6.3],\n",
    "            'C': ['a', 'b', 'c']\n",
    "        }\n",
    "\n",
    "        self.data2 = {\n",
    "            'B': [7, 8, 9],\n",
    "            'A': [1.1, 2.2, 3.3],\n",
    "            'D': ['x', 'y', 'z']\n",
    "        }\n",
    "\n",
    "        self.df1 = pd.DataFrame(self.data1)\n",
    "        self.df2 = pd.DataFrame(self.data2)\n",
    "\n",
    "    def test_compare_columns(self):\n",
    "        not_in_common, diff_order = compare_columns(self.df1, self.df2)\n",
    "        self.assertEqual(not_in_common, ['C', 'D'])\n",
    "        self.assertEqual(diff_order, ['A', 'B'])\n",
    "\n",
    "    def test_compare_data_types(self):\n",
    "        common_columns = list(set(self.df1.columns) & set(self.df2.columns))\n",
    "        diff_data_types = compare_data_types(self.df1, self.df2, common_columns)\n",
    "        self.assertEqual(diff_data_types, ['A', 'B'])\n",
    "\n",
    "    def test_get_sample_values(self):\n",
    "        common_columns = list(set(self.df1.columns) & set(self.df2.columns))\n",
    "        diff_data_types = compare_data_types(self.df1, self.df2, common_columns)\n",
    "        get_sample_values(self.df1, self.df2, diff_data_types)  # This test is only to check if the function executes without errors\n",
    "\n",
    "    def test_data_profile_comparison(self):\n",
    "        data_profile_comparison(self.df1, self.df2)  # This test is only to check if the function executes without errors\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I don't like this function testing solution. I much preferred working off an earlier one. I'll add the results from the earlier assay at a later date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations/Recommendations:\n",
    "# -- You can create a whole solution from an initial set of asks.\n",
    "# -- You can ask for tests to exercise the solution.\n",
    "# -- You can get wildly different solution based on the same prompt.\n",
    "# --   So, good idea to save off the solution that you generate and like\n",
    "# -- Modify the prompt to get different solutions, some with better solutions, and explore the universe of solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aqpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
