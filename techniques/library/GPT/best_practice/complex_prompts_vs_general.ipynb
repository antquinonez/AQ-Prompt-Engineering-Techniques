{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAIResponseParser' from 'OpenAIResponseParser' (/home/aq/Documents/Source/AQ-Prompt-Engineering-Techniques/techniques/library/lib/OpenAIResponseParser.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(lib)\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mMessageParser\u001b[39;00m \u001b[39mimport\u001b[39;00m MessageParser\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mOpenAIResponseParser\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIResponseParser\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAIResponseParser' from 'OpenAIResponseParser' (/home/aq/Documents/Source/AQ-Prompt-Engineering-Techniques/techniques/library/lib/OpenAIResponseParser.py)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "lib = os.path.abspath(os.path.join('..', '..', 'lib'))\n",
    "sys.path.append(lib)\n",
    "\n",
    "from MessageParser import MessageParser\n",
    "from OpenAIResponseParser import OpenAIResponseParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Certainly! Here's a Python code for generating the Fibonacci sequence:\\n\\n```\\ndef fibonacci_sequence(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    else:\\n        result = [0, 1]\\n        for i in range(2, n):\\n            sum = result[i-1] + result[i-2]\\n            result.append(sum)\\n        return result\\n\\nprint(fibonacci_sequence(10))\\n```\\n\\nOutput:\\n```\\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\\n```\\n\\nHere, we have created a function named `fibonacci_sequence`, which takes a number `n` as input and returns a list containing the first `n` numbers in the Fibonacci sequence. In this code, we are initializing the result list to `[0, 1]`, as the first two numbers in the sequence are always 0 and 1. Then we iterate through the range `2` to `n` and calculate each Fibonacci number as the sum of the previous two numbers. Finally, we append each new number to the result list and return it at the end of the function.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1681025804,\n",
      "  \"id\": \"chatcmpl-73JtMRETnD8fWbTMawEPKTdgtdKEZ\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 253,\n",
      "    \"prompt_tokens\": 26,\n",
      "    \"total_tokens\": 279\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "ShapeError",
     "evalue": "unable to vstack, dtypes for column \"role\" don't match: `f32` and `str`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mShapeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(response)\n\u001b[1;32m     16\u001b[0m parser \u001b[39m=\u001b[39m OpenAIResponseParser(response)\n\u001b[0;32m---> 17\u001b[0m messages_df \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mextract_messages()\n\u001b[1;32m     18\u001b[0m messages_df\n",
      "File \u001b[0;32m~/Documents/Source/AQ-Prompt-Engineering-Techniques/techniques/library/lib/OpenAIResponseParser.py:23\u001b[0m, in \u001b[0;36mextract_messages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstore_response\u001b[39m(\u001b[39mself\u001b[39m, response):\n\u001b[1;32m     19\u001b[0m     content \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mvstack(\n\u001b[1;32m     22\u001b[0m         pl\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m---> 23\u001b[0m             {\n\u001b[1;32m     24\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: [response[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m     25\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m: [response[\u001b[39m'\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m     26\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: [response[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m     27\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39musage\u001b[39m\u001b[39m\"\u001b[39m: [response[\u001b[39m'\u001b[39m\u001b[39musage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mprompt_tokens\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m     28\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: [response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m     29\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: [content],\n\u001b[1;32m     30\u001b[0m             }\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     32\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/aqpe/lib/python3.11/site-packages/polars/dataframe/frame.py:5483\u001b[0m, in \u001b[0;36mDataFrame.vstack\u001b[0;34m(self, df, in_place)\u001b[0m\n\u001b[1;32m   5481\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   5482\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 5483\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_from_pydf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_df\u001b[39m.\u001b[39;49mvstack(df\u001b[39m.\u001b[39;49m_df))\n",
      "\u001b[0;31mShapeError\u001b[0m: unable to vstack, dtypes for column \"role\" don't match: `f32` and `str`"
     ]
    }
   ],
   "source": [
    "# Set the API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "text = \"\"\"\n",
    "system: You are  a software expert.\n",
    "user: write python code for fibonacci sequence\n",
    "\"\"\"\n",
    "\n",
    "parser = MessageParser(text)\n",
    "messages = parser.parse_messages()\n",
    "\n",
    "# Get the answer\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo', temperature=1.3, max_tokens=3000, messages = messages)\n",
    "print(response)\n",
    "\n",
    "parser = OpenAIResponseParser(response)\n",
    "messages_df = parser.extract_messages()\n",
    "messages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "\n",
    "# image_resp = openai.Image.create(prompt=\"blonde woman, wearing pink blouse, wind blowing\", n=4, size=\"512x512\")\n",
    "# image_resp\n",
    "\n",
    "# # function to save the image in the image_resp object\n",
    "\n",
    "# import datetime\n",
    "# import arrow\n",
    "\n",
    "# # iterate and enumerate through the images\n",
    "# for i, dict in enumerate(image_resp['data']):\n",
    "#     url = (dict['url'])\n",
    "\n",
    "#     # get current date and time as a string, using arrow library\n",
    "#     now = arrow.now().format('YYYY-MM-DD-HH-mm-ss')\n",
    "    \n",
    "#     # assign a name to the image\n",
    "#     name = \"image_\" + now + \".png\"\n",
    "\n",
    "#     # save the image\n",
    "#     with open(name, 'wb') as f:\n",
    "#         f.write(requests.get(url).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aqpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
