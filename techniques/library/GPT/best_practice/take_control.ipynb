{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Control of GPT : Use the API. Don't let the API use you"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My first openai API Project!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I use the openai Python lib and some custom classes to handle processing prompts and responses. I store the results in a pandas dataframe, then format the code in a pandas 'style' object. I can use the dataframe and other objects (like the multiline string of prompts) to manage context for later prompts. Yes, context from prompts and answers. So much more to do with this. But this is a start."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    /* Enable word wrap */\n",
       "    .rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "      white-space: nowrap;\n",
       "      overflow: hidden;\n",
       "      text-overflow: ellipsis;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    /* Enable word wrap */\n",
    "    .rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
    "      white-space: nowrap;\n",
    "      overflow: hidden;\n",
    "      text-overflow: ellipsis;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "import openai\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "\n",
    "lib = os.path.abspath(os.path.join('..', '..', 'libs'))\n",
    "sys.path.append(lib)\n",
    "\n",
    "from MessageParser import MessageParser\n",
    "from ResponseParser import ResponseParser\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n",
    "# *******************************************************************************************************\n",
    "# SET THE API KEY\n",
    "# ================\n",
    "# -- set the env variable OPENAI_API_KEY to your OpenAI API key       <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# *******************************************************************************************************\n",
    "\n",
    "# Setup up pandas properties\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent line break in DataFrame\n",
    "pd.set_option('display.max_colwidth', None)  # Display the full content of cells\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the system prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_list = []\n",
    "sys_prompt_1 = \"\"\"You are a software expert.\"\"\"\n",
    "sys_prompt_2 = \"\"\"Use. \"```python\" style for code blocks.\"\"\"\n",
    "sys_prompt_3 = \"\"\"Include the name for a file where I would store individual code for functions or classes.\"\"\"\n",
    "sys_prompt_4 = \"\"\"Embed in the body of the code block the instructions you created prepended with a '\\n'.\"\"\"\n",
    "\n",
    "sys_prompt_list.append(sys_prompt_1)\n",
    "sys_prompt_list.append(sys_prompt_2)\n",
    "sys_prompt_list.append(sys_prompt_3)\n",
    "sys_prompt_list.append(sys_prompt_4)\n",
    "\n",
    "sys_prompt = \"\".join(sys_prompt_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the message and make the call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = f\"\"\"\n",
    "system: {sys_prompt}\n",
    "user: Write python code for fibonacci sequence. also write a function to zero pad a string to 10 chars.\n",
    "\"\"\"\n",
    "\n",
    "parser = MessageParser(prompts)\n",
    "messages = parser.parse_messages()\n",
    "\n",
    "# Get the response\n",
    "# I'll abstract this away in the future\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo', temperature=1.3, max_tokens=300, messages = messages)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a parser object, using a custom class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ResponseParser(response=response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a pandas dataframe from the parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = parser.get_log_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pandas style applies custom formatting to a DataFrame to make it easier to read and\n",
    "# understand. It does not offer the full range of functionality that a DataFrame provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b75dc_row0_col0, #T_b75dc_row0_col1, #T_b75dc_row0_col2, #T_b75dc_row0_col3, #T_b75dc_row0_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b75dc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b75dc_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_b75dc_level0_col1\" class=\"col_heading level0 col1\" >created</th>\n",
       "      <th id=\"T_b75dc_level0_col2\" class=\"col_heading level0 col2\" >model</th>\n",
       "      <th id=\"T_b75dc_level0_col3\" class=\"col_heading level0 col3\" >usage</th>\n",
       "      <th id=\"T_b75dc_level0_col4\" class=\"col_heading level0 col4\" >all_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b75dc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b75dc_row0_col0\" class=\"data row0 col0\" >chatcmpl-73v9FHH2bnrxZOT4rIixo3uSWRB4I</td>\n",
       "      <td id=\"T_b75dc_row0_col1\" class=\"data row0 col1\" >1681169017.000000</td>\n",
       "      <td id=\"T_b75dc_row0_col2\" class=\"data row0 col2\" >gpt-3.5-turbo-0301</td>\n",
       "      <td id=\"T_b75dc_row0_col3\" class=\"data row0 col3\" >82.000000</td>\n",
       "      <td id=\"T_b75dc_row0_col4\" class=\"data row0 col4\" >#&nbsp;storing&nbsp;fibonacci&nbsp;sequence&nbsp;up&nbsp;to&nbsp;nth&nbsp;number<br>def&nbsp;fibonacci(n:&nbsp;int)&nbsp;->&nbsp;list:<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;0:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;[]<br>&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;n&nbsp;==&nbsp;1:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;[0]<br>&nbsp;&nbsp;&nbsp;&nbsp;seq&nbsp;=&nbsp;[0,&nbsp;1]<br>&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;len(seq)&nbsp;<&nbsp;n:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;seq.append(seq[-1]&nbsp;+&nbsp;seq[-2])<br>&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;seq<br><br>#&nbsp;getting&nbsp;random&nbsp;number&nbsp;count&nbsp;and&nbsp;printing&nbsp;the&nbsp;fibonacci&nbsp;sequence<br>import&nbsp;random<br>n&nbsp;=&nbsp;random.randint(1,&nbsp;20)<br>seq&nbsp;=&nbsp;fibonacci(n)<br>print(f\"Fibonacci&nbsp;sequence&nbsp;up&nbsp;to&nbsp;{n}:\")<br>print(seq)<br>def&nbsp;zero_pad(s:&nbsp;str)&nbsp;->&nbsp;str:<br>&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;p&nbsp;=&nbsp;10&nbsp;-&nbsp;len(s)<br>&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;'0'*p&nbsp;+&nbsp;s<br><br>#&nbsp;Testing&nbsp;with&nbsp;a&nbsp;sample&nbsp;string<br>s&nbsp;=&nbsp;\"hello\"<br>padded_s&nbsp;=&nbsp;zero_pad(s)<br>print(f\"Before&nbsp;Padding:&nbsp;'{s}'\\nAfter&nbsp;Padding:&nbsp;'{padded_s}'\")<br></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2680343aa10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.styled_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23b8fda9da3a2a104a5aa7aa75e01582a86c23885ba37bc31bb5dabaa9da29ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
